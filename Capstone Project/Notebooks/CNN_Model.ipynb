{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the preprocessed data from previous notebook\n",
    "\n",
    "%store -r x_train \n",
    "%store -r x_test \n",
    "%store -r y_train \n",
    "%store -r y_test \n",
    "%store -r yy \n",
    "%store -r le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNs require a fixed size for all inputs. To overcome this we will zero pad the output vectors to make them all the same size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "max_pad_len = 174\n",
    "\n",
    "def extract_features(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None \n",
    "     \n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction from  8732  files\n"
     ]
    }
   ],
   "source": [
    "# Load various imports \n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "# Set the path to the full UrbanSound dataset \n",
    "fulldatasetpath = '../UrbanSound Dataset sample'\n",
    "\n",
    "metadata = pd.read_csv('../UrbanSound Dataset sample/UrbanSound8K.csv')\n",
    "\n",
    "features = []\n",
    "\n",
    "# Iterate through each sound file and extract the features \n",
    "for index, row in metadata.iterrows():\n",
    "    \n",
    "    file_name = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
    "    \n",
    "    class_label = row[\"class_name\"]\n",
    "    data = extract_features(file_name)\n",
    "    \n",
    "    features.append([data, class_label])\n",
    "\n",
    "# Convert into a Panda dataframe \n",
    "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "\n",
    "print('Finished feature extraction from ', len(featuresdf), ' files') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/CTR/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/CTR/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/CTR/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/CTR/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/CTR/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/CTR/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "y = np.array(featuresdf.class_label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y)) \n",
    "\n",
    "# split the dataset \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/CTR/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "\n",
    "num_rows = 40\n",
    "num_columns = 174\n",
    "num_channels = 1\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n",
    "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "num_labels = yy.shape[1]\n",
    "filter_size = 2\n",
    "\n",
    "# Construct model \n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 39, 173, 16)       80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 19, 86, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 19, 86, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 18, 85, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 9, 42, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 9, 42, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 41, 64)         8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 20, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 20, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 19, 128)        32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 44,602\n",
      "Trainable params: 44,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1747/1747 [==============================] - 1s 346us/step\n",
      "Pre-training accuracy: 7.4986%\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/CTR/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 6985 samples, validate on 1747 samples\n",
      "Epoch 1/72\n",
      "6985/6985 [==============================] - 13s 2ms/step - loss: 4.5383 - accuracy: 0.1585 - val_loss: 2.0801 - val_accuracy: 0.2702\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.08014, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 2/72\n",
      "6985/6985 [==============================] - 13s 2ms/step - loss: 1.9515 - accuracy: 0.3014 - val_loss: 1.9496 - val_accuracy: 0.3446\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.08014 to 1.94956, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 3/72\n",
      "6985/6985 [==============================] - 13s 2ms/step - loss: 1.6448 - accuracy: 0.4099 - val_loss: 1.7211 - val_accuracy: 0.4282\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.94956 to 1.72106, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 4/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 1.4807 - accuracy: 0.4783 - val_loss: 1.5916 - val_accuracy: 0.4488\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.72106 to 1.59165, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 5/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 1.3573 - accuracy: 0.5160 - val_loss: 1.4835 - val_accuracy: 0.5037\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.59165 to 1.48346, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 6/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 1.2817 - accuracy: 0.5533 - val_loss: 1.3728 - val_accuracy: 0.5375\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.48346 to 1.37276, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 7/72\n",
      "6985/6985 [==============================] - 13s 2ms/step - loss: 1.1988 - accuracy: 0.5759 - val_loss: 1.3234 - val_accuracy: 0.5404\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.37276 to 1.32341, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 8/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 1.1346 - accuracy: 0.6029 - val_loss: 1.2682 - val_accuracy: 0.5638\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.32341 to 1.26822, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 9/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 1.0896 - accuracy: 0.6176 - val_loss: 1.1886 - val_accuracy: 0.5902\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.26822 to 1.18858, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 10/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 1.0397 - accuracy: 0.6377 - val_loss: 1.1484 - val_accuracy: 0.5924\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.18858 to 1.14839, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 11/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 1.0007 - accuracy: 0.6530 - val_loss: 1.1308 - val_accuracy: 0.5953\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.14839 to 1.13079, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 12/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.9432 - accuracy: 0.6746 - val_loss: 1.0946 - val_accuracy: 0.6159\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.13079 to 1.09462, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 13/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.9187 - accuracy: 0.6840 - val_loss: 1.0250 - val_accuracy: 0.6485\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.09462 to 1.02497, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 14/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.8829 - accuracy: 0.7058 - val_loss: 1.0156 - val_accuracy: 0.6537\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.02497 to 1.01561, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 15/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.8494 - accuracy: 0.7110 - val_loss: 0.9776 - val_accuracy: 0.6577\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.01561 to 0.97761, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 16/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.8297 - accuracy: 0.7120 - val_loss: 0.9715 - val_accuracy: 0.6875\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.97761 to 0.97150, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 17/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.8119 - accuracy: 0.7267 - val_loss: 0.8881 - val_accuracy: 0.7127\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.97150 to 0.88813, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 18/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.7722 - accuracy: 0.7330 - val_loss: 0.9052 - val_accuracy: 0.7052\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.88813\n",
      "Epoch 19/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.7473 - accuracy: 0.7515 - val_loss: 0.8652 - val_accuracy: 0.7235\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.88813 to 0.86520, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 20/72\n",
      "6985/6985 [==============================] - 16s 2ms/step - loss: 0.7278 - accuracy: 0.7515 - val_loss: 0.8647 - val_accuracy: 0.7167\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.86520 to 0.86472, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 21/72\n",
      "6985/6985 [==============================] - 16s 2ms/step - loss: 0.7132 - accuracy: 0.7548 - val_loss: 0.7856 - val_accuracy: 0.7476\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.86472 to 0.78562, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 22/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.6912 - accuracy: 0.7638 - val_loss: 0.8363 - val_accuracy: 0.7333\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.78562\n",
      "Epoch 23/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.6806 - accuracy: 0.7717 - val_loss: 0.7851 - val_accuracy: 0.7487\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.78562 to 0.78509, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 24/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.6652 - accuracy: 0.7717 - val_loss: 0.8080 - val_accuracy: 0.7327\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.78509\n",
      "Epoch 25/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.6470 - accuracy: 0.7772 - val_loss: 0.7420 - val_accuracy: 0.7710\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.78509 to 0.74202, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 26/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.6198 - accuracy: 0.7921 - val_loss: 0.7370 - val_accuracy: 0.7676\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.74202 to 0.73704, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 27/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.5996 - accuracy: 0.7956 - val_loss: 0.7774 - val_accuracy: 0.7567\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.73704\n",
      "Epoch 28/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.5892 - accuracy: 0.8016 - val_loss: 0.7226 - val_accuracy: 0.7710\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.73704 to 0.72257, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 29/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.5672 - accuracy: 0.8077 - val_loss: 0.7642 - val_accuracy: 0.7602\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.72257\n",
      "Epoch 30/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.5563 - accuracy: 0.8163 - val_loss: 0.7637 - val_accuracy: 0.7407\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.72257\n",
      "Epoch 31/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.5601 - accuracy: 0.8146 - val_loss: 0.7138 - val_accuracy: 0.7750\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.72257 to 0.71378, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 32/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.5369 - accuracy: 0.8225 - val_loss: 0.6901 - val_accuracy: 0.7888\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.71378 to 0.69010, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 33/72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.5239 - accuracy: 0.8173 - val_loss: 0.6445 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.69010 to 0.64446, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 34/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.5100 - accuracy: 0.8271 - val_loss: 0.6968 - val_accuracy: 0.7773\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.64446\n",
      "Epoch 35/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.5083 - accuracy: 0.8301 - val_loss: 0.6650 - val_accuracy: 0.7905\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.64446\n",
      "Epoch 36/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.4836 - accuracy: 0.8372 - val_loss: 0.6555 - val_accuracy: 0.7974\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.64446\n",
      "Epoch 37/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.4846 - accuracy: 0.8379 - val_loss: 0.7026 - val_accuracy: 0.7762\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.64446\n",
      "Epoch 38/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.4803 - accuracy: 0.8399 - val_loss: 0.5875 - val_accuracy: 0.8157\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.64446 to 0.58752, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 39/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.4569 - accuracy: 0.8428 - val_loss: 0.5980 - val_accuracy: 0.8197\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.58752\n",
      "Epoch 40/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.4514 - accuracy: 0.8405 - val_loss: 0.5399 - val_accuracy: 0.8380\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.58752 to 0.53986, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 41/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.4550 - accuracy: 0.8431 - val_loss: 0.5428 - val_accuracy: 0.8357\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.53986\n",
      "Epoch 42/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.4375 - accuracy: 0.8501 - val_loss: 0.5663 - val_accuracy: 0.8226\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.53986\n",
      "Epoch 43/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.4005 - accuracy: 0.8620 - val_loss: 0.6328 - val_accuracy: 0.7985\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.53986\n",
      "Epoch 44/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.4219 - accuracy: 0.8567 - val_loss: 0.6061 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.53986\n",
      "Epoch 45/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.4096 - accuracy: 0.8594 - val_loss: 0.6248 - val_accuracy: 0.8077\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.53986\n",
      "Epoch 46/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.3939 - accuracy: 0.8680 - val_loss: 0.5763 - val_accuracy: 0.8231\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.53986\n",
      "Epoch 47/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.3919 - accuracy: 0.8669 - val_loss: 0.5069 - val_accuracy: 0.8477\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.53986 to 0.50694, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 48/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.3797 - accuracy: 0.8716 - val_loss: 0.5178 - val_accuracy: 0.8380\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.50694\n",
      "Epoch 49/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.3695 - accuracy: 0.8720 - val_loss: 0.5336 - val_accuracy: 0.8294\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.50694\n",
      "Epoch 50/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.3641 - accuracy: 0.8754 - val_loss: 0.5182 - val_accuracy: 0.8374\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.50694\n",
      "Epoch 51/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.3574 - accuracy: 0.8796 - val_loss: 0.5395 - val_accuracy: 0.8243\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.50694\n",
      "Epoch 52/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.3687 - accuracy: 0.8703 - val_loss: 0.5412 - val_accuracy: 0.8288\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.50694\n",
      "Epoch 53/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.3522 - accuracy: 0.8795 - val_loss: 0.5576 - val_accuracy: 0.8226\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.50694\n",
      "Epoch 54/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.3502 - accuracy: 0.8773 - val_loss: 0.4356 - val_accuracy: 0.8666\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.50694 to 0.43559, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 55/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.3490 - accuracy: 0.8812 - val_loss: 0.5748 - val_accuracy: 0.8226\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.43559\n",
      "Epoch 56/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.3247 - accuracy: 0.8909 - val_loss: 0.5503 - val_accuracy: 0.8208\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.43559\n",
      "Epoch 57/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.3283 - accuracy: 0.8876 - val_loss: 0.6427 - val_accuracy: 0.8042\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.43559\n",
      "Epoch 58/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.3460 - accuracy: 0.8799 - val_loss: 0.4690 - val_accuracy: 0.8563\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.43559\n",
      "Epoch 59/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.3149 - accuracy: 0.8935 - val_loss: 0.4921 - val_accuracy: 0.8454\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.43559\n",
      "Epoch 60/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.3236 - accuracy: 0.8876 - val_loss: 0.4955 - val_accuracy: 0.8443\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.43559\n",
      "Epoch 61/72\n",
      "6985/6985 [==============================] - 14s 2ms/step - loss: 0.3055 - accuracy: 0.8958 - val_loss: 0.4147 - val_accuracy: 0.8706\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.43559 to 0.41470, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 62/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.3034 - accuracy: 0.8968 - val_loss: 0.4346 - val_accuracy: 0.8655\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.41470\n",
      "Epoch 63/72\n",
      "6985/6985 [==============================] - 16s 2ms/step - loss: 0.2961 - accuracy: 0.9002 - val_loss: 0.4498 - val_accuracy: 0.8517\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.41470\n",
      "Epoch 64/72\n",
      "6985/6985 [==============================] - 16s 2ms/step - loss: 0.2951 - accuracy: 0.8951 - val_loss: 0.4223 - val_accuracy: 0.8689\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.41470\n",
      "Epoch 65/72\n",
      "6985/6985 [==============================] - 17s 3ms/step - loss: 0.2864 - accuracy: 0.8988 - val_loss: 0.4414 - val_accuracy: 0.8592\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.41470\n",
      "Epoch 66/72\n",
      "6985/6985 [==============================] - 17s 2ms/step - loss: 0.2955 - accuracy: 0.9028 - val_loss: 0.4299 - val_accuracy: 0.8678\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.41470\n",
      "Epoch 67/72\n",
      "6985/6985 [==============================] - 16s 2ms/step - loss: 0.2806 - accuracy: 0.9012 - val_loss: 0.4361 - val_accuracy: 0.8615\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.41470\n",
      "Epoch 68/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.2713 - accuracy: 0.9087 - val_loss: 0.4547 - val_accuracy: 0.8529\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.41470\n",
      "Epoch 69/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.2587 - accuracy: 0.9117 - val_loss: 0.4300 - val_accuracy: 0.8632\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.41470\n",
      "Epoch 70/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.2634 - accuracy: 0.9092 - val_loss: 0.4398 - val_accuracy: 0.8615\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.41470\n",
      "Epoch 71/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.2519 - accuracy: 0.9125 - val_loss: 0.4513 - val_accuracy: 0.8586\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.41470\n",
      "Epoch 72/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.2476 - accuracy: 0.9140 - val_loss: 0.3937 - val_accuracy: 0.8712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00072: val_loss improved from 0.41470 to 0.39369, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Training completed in time:  0:17:04.089576\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "from datetime import datetime \n",
    "\n",
    "#num_epochs = 12\n",
    "#num_batch_size = 128\n",
    "\n",
    "num_epochs = 72\n",
    "num_batch_size = 256\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_cnn.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9324266314506531\n",
      "Testing Accuracy:  0.8712077736854553\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction(file_name):\n",
    "    prediction_feature = extract_features(file_name) \n",
    "    prediction_feature = prediction_feature.reshape(1, num_rows, num_columns, num_channels)\n",
    "\n",
    "    predicted_vector = model.predict_classes(prediction_feature)\n",
    "    predicted_class = le.inverse_transform(predicted_vector) \n",
    "    print(\"The predicted class is:\", predicted_class[0], '\\n') \n",
    "\n",
    "    predicted_proba_vector = model.predict_proba(prediction_feature) \n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    for i in range(len(predicted_proba)): \n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: air_conditioner \n",
      "\n",
      "air_conditioner \t\t :  0.99563133716583251953125000000000\n",
      "car_horn \t\t :  0.00020358270558062940835952758789\n",
      "children_playing \t\t :  0.00022027218074072152376174926758\n",
      "dog_bark \t\t :  0.00001087700547941494733095169067\n",
      "drilling \t\t :  0.00207596528343856334686279296875\n",
      "engine_idling \t\t :  0.00026502329274080693721771240234\n",
      "gun_shot \t\t :  0.00004613533019437454640865325928\n",
      "jackhammer \t\t :  0.00087470823200419545173645019531\n",
      "siren \t\t :  0.00000142599765240447595715522766\n",
      "street_music \t\t :  0.00067064189352095127105712890625\n"
     ]
    }
   ],
   "source": [
    "# Class: Air Conditioner\n",
    "\n",
    "filename = '../UrbanSound Dataset sample/audio/100852-0-0-0.wav' \n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: drilling \n",
      "\n",
      "air_conditioner \t\t :  0.00000042938685851368063595145941\n",
      "car_horn \t\t :  0.00004225774682709015905857086182\n",
      "children_playing \t\t :  0.00000014005190962507185759022832\n",
      "dog_bark \t\t :  0.00000000305991920690473762078909\n",
      "drilling \t\t :  0.99971979856491088867187500000000\n",
      "engine_idling \t\t :  0.00000000353655948970299505162984\n",
      "gun_shot \t\t :  0.00000000008939533141516520231562\n",
      "jackhammer \t\t :  0.00001107652587961638346314430237\n",
      "siren \t\t :  0.00000035053454894296010024845600\n",
      "street_music \t\t :  0.00022583712416235357522964477539\n"
     ]
    }
   ],
   "source": [
    "# Class: Drilling\n",
    "\n",
    "filename = '../UrbanSound Dataset sample/audio/103199-4-0-0.wav'\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: street_music \n",
      "\n",
      "air_conditioner \t\t :  0.00833441503345966339111328125000\n",
      "car_horn \t\t :  0.00465157674625515937805175781250\n",
      "children_playing \t\t :  0.04517330974340438842773437500000\n",
      "dog_bark \t\t :  0.00047527611604891717433929443359\n",
      "drilling \t\t :  0.00010076705802930518984794616699\n",
      "engine_idling \t\t :  0.00000989730506262276321649551392\n",
      "gun_shot \t\t :  0.00000000005706900924051794277148\n",
      "jackhammer \t\t :  0.00000185486965165182482451200485\n",
      "siren \t\t :  0.00284131290391087532043457031250\n",
      "street_music \t\t :  0.93841165304183959960937500000000\n"
     ]
    }
   ],
   "source": [
    "# Class: Street music \n",
    "\n",
    "filename = '../UrbanSound Dataset sample/audio/101848-9-0-0.wav'\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: drilling \n",
      "\n",
      "air_conditioner \t\t :  0.00284333573654294013977050781250\n",
      "car_horn \t\t :  0.20432898402214050292968750000000\n",
      "children_playing \t\t :  0.00917182397097349166870117187500\n",
      "dog_bark \t\t :  0.15067791938781738281250000000000\n",
      "drilling \t\t :  0.23780646920204162597656250000000\n",
      "engine_idling \t\t :  0.01807190477848052978515625000000\n",
      "gun_shot \t\t :  0.16262696683406829833984375000000\n",
      "jackhammer \t\t :  0.18306092917919158935546875000000\n",
      "siren \t\t :  0.02403151430189609527587890625000\n",
      "street_music \t\t :  0.00738012418150901794433593750000\n"
     ]
    }
   ],
   "source": [
    "# Class: Car Horn \n",
    "\n",
    "filename = '../UrbanSound Dataset sample/audio/100648-1-0-0.wav'\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: dog_bark \n",
      "\n",
      "air_conditioner \t\t :  0.00006136990123195573687553405762\n",
      "car_horn \t\t :  0.00024994436535052955150604248047\n",
      "children_playing \t\t :  0.00098140211775898933410644531250\n",
      "dog_bark \t\t :  0.99002712965011596679687500000000\n",
      "drilling \t\t :  0.00452040135860443115234375000000\n",
      "engine_idling \t\t :  0.00012656371109187602996826171875\n",
      "gun_shot \t\t :  0.00106266024522483348846435546875\n",
      "jackhammer \t\t :  0.00000228182352657313458621501923\n",
      "siren \t\t :  0.00006977697921684011816978454590\n",
      "street_music \t\t :  0.00289859389886260032653808593750\n"
     ]
    }
   ],
   "source": [
    "filename = '../Evaluation audio/dog_bark_1.wav'\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: jackhammer \n",
      "\n",
      "air_conditioner \t\t :  0.02930284291505813598632812500000\n",
      "car_horn \t\t :  0.01064816582947969436645507812500\n",
      "children_playing \t\t :  0.00097187329083681106567382812500\n",
      "dog_bark \t\t :  0.00353058939799666404724121093750\n",
      "drilling \t\t :  0.00866227783262729644775390625000\n",
      "engine_idling \t\t :  0.00768750114366412162780761718750\n",
      "gun_shot \t\t :  0.00006228521669982001185417175293\n",
      "jackhammer \t\t :  0.93893104791641235351562500000000\n",
      "siren \t\t :  0.00011614457616815343499183654785\n",
      "street_music \t\t :  0.00008724664803594350814819335938\n"
     ]
    }
   ],
   "source": [
    "filename = '../Evaluation audio/drilling_1.wav'\n",
    "\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: gun_shot \n",
      "\n",
      "air_conditioner \t\t :  0.00000002894428874355980951804668\n",
      "car_horn \t\t :  0.00007518471829826012253761291504\n",
      "children_playing \t\t :  0.00016089688870124518871307373047\n",
      "dog_bark \t\t :  0.00235235667787492275238037109375\n",
      "drilling \t\t :  0.03010236844420433044433593750000\n",
      "engine_idling \t\t :  0.00256270007230341434478759765625\n",
      "gun_shot \t\t :  0.96351563930511474609375000000000\n",
      "jackhammer \t\t :  0.00000104830974123615305870771408\n",
      "siren \t\t :  0.00107238197233527898788452148438\n",
      "street_music \t\t :  0.00015743463882245123386383056641\n"
     ]
    }
   ],
   "source": [
    "filename = '../Evaluation audio/gun_shot_1.wav'\n",
    "\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
