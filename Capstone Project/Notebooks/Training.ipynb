{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r x_train \n",
    "%store -r x_test \n",
    "%store -r y_train \n",
    "%store -r y_test \n",
    "%store -r yy \n",
    "%store -r le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start off using MLP architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/CTR/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/CTR/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/CTR/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/CTR/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/CTR/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/CTR/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/CTR/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "\n",
    "num_labels = yy.shape[1]\n",
    "filter_size = 2\n",
    "\n",
    "# Construct model \n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(256, input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               10496     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 78,858\n",
      "Trainable params: 78,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pre-training accuracy: 10.8758%\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6985 samples, validate on 1747 samples\n",
      "Epoch 1/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 1.8796 - accuracy: 0.3664 - val_loss: 1.5983 - val_accuracy: 0.4974\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.59828, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 2/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 1.7008 - accuracy: 0.4251 - val_loss: 1.4263 - val_accuracy: 0.5507\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.59828 to 1.42625, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 3/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 1.5595 - accuracy: 0.4621 - val_loss: 1.3404 - val_accuracy: 0.5724\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.42625 to 1.34036, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 4/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 1.4303 - accuracy: 0.5160 - val_loss: 1.1838 - val_accuracy: 0.6222\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.34036 to 1.18377, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 5/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 1.3599 - accuracy: 0.5407 - val_loss: 1.1099 - val_accuracy: 0.6440\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.18377 to 1.10990, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 6/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 1.3118 - accuracy: 0.5555 - val_loss: 1.0843 - val_accuracy: 0.6617\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.10990 to 1.08426, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 7/100\n",
      "6985/6985 [==============================] - 0s 55us/step - loss: 1.2339 - accuracy: 0.5795 - val_loss: 1.0389 - val_accuracy: 0.6560\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.08426 to 1.03893, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 8/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 1.1867 - accuracy: 0.5921 - val_loss: 0.9718 - val_accuracy: 0.6955\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.03893 to 0.97175, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 9/100\n",
      "6985/6985 [==============================] - 0s 55us/step - loss: 1.1387 - accuracy: 0.6133 - val_loss: 0.9160 - val_accuracy: 0.7069\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.97175 to 0.91600, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 10/100\n",
      "6985/6985 [==============================] - 0s 55us/step - loss: 1.1112 - accuracy: 0.6180 - val_loss: 0.8876 - val_accuracy: 0.7304\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.91600 to 0.88762, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 11/100\n",
      "6985/6985 [==============================] - 0s 55us/step - loss: 1.0852 - accuracy: 0.6302 - val_loss: 0.8563 - val_accuracy: 0.7418\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.88762 to 0.85634, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 12/100\n",
      "6985/6985 [==============================] - 0s 59us/step - loss: 1.0133 - accuracy: 0.6590 - val_loss: 0.7958 - val_accuracy: 0.7516\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.85634 to 0.79576, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 13/100\n",
      "6985/6985 [==============================] - 0s 55us/step - loss: 0.9946 - accuracy: 0.6651 - val_loss: 0.7959 - val_accuracy: 0.7510\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.79576\n",
      "Epoch 14/100\n",
      "6985/6985 [==============================] - 0s 55us/step - loss: 0.9661 - accuracy: 0.6756 - val_loss: 0.7898 - val_accuracy: 0.7510\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.79576 to 0.78981, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 15/100\n",
      "6985/6985 [==============================] - 0s 58us/step - loss: 0.9581 - accuracy: 0.6807 - val_loss: 0.7612 - val_accuracy: 0.7779\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.78981 to 0.76121, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 16/100\n",
      "6985/6985 [==============================] - 0s 60us/step - loss: 0.9277 - accuracy: 0.6903 - val_loss: 0.7173 - val_accuracy: 0.7825\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.76121 to 0.71730, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 17/100\n",
      "6985/6985 [==============================] - 0s 60us/step - loss: 0.9036 - accuracy: 0.6956 - val_loss: 0.7431 - val_accuracy: 0.7750\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.71730\n",
      "Epoch 18/100\n",
      "6985/6985 [==============================] - 0s 58us/step - loss: 0.8895 - accuracy: 0.6999 - val_loss: 0.7088 - val_accuracy: 0.7911\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.71730 to 0.70881, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 19/100\n",
      "6985/6985 [==============================] - 0s 58us/step - loss: 0.8757 - accuracy: 0.7024 - val_loss: 0.6875 - val_accuracy: 0.7945\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.70881 to 0.68748, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 20/100\n",
      "6985/6985 [==============================] - 0s 63us/step - loss: 0.8488 - accuracy: 0.7157 - val_loss: 0.6590 - val_accuracy: 0.7842\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.68748 to 0.65901, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 21/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.8621 - accuracy: 0.7098 - val_loss: 0.6486 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.65901 to 0.64856, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 22/100\n",
      "6985/6985 [==============================] - 0s 58us/step - loss: 0.8159 - accuracy: 0.7228 - val_loss: 0.6554 - val_accuracy: 0.7985\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.64856\n",
      "Epoch 23/100\n",
      "6985/6985 [==============================] - 0s 60us/step - loss: 0.8138 - accuracy: 0.7248 - val_loss: 0.6548 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.64856\n",
      "Epoch 24/100\n",
      "6985/6985 [==============================] - 0s 57us/step - loss: 0.7974 - accuracy: 0.7248 - val_loss: 0.6308 - val_accuracy: 0.8088\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.64856 to 0.63079, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 25/100\n",
      "6985/6985 [==============================] - 0s 59us/step - loss: 0.7821 - accuracy: 0.7329 - val_loss: 0.6252 - val_accuracy: 0.8168\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.63079 to 0.62521, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 26/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 0.7569 - accuracy: 0.7417 - val_loss: 0.5848 - val_accuracy: 0.8266\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.62521 to 0.58480, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 27/100\n",
      "6985/6985 [==============================] - 0s 55us/step - loss: 0.7669 - accuracy: 0.7396 - val_loss: 0.5896 - val_accuracy: 0.8094\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.58480\n",
      "Epoch 28/100\n",
      "6985/6985 [==============================] - 0s 60us/step - loss: 0.7450 - accuracy: 0.7439 - val_loss: 0.5973 - val_accuracy: 0.8231\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.58480\n",
      "Epoch 29/100\n",
      "6985/6985 [==============================] - 0s 58us/step - loss: 0.7423 - accuracy: 0.7472 - val_loss: 0.5799 - val_accuracy: 0.8283\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.58480 to 0.57990, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 30/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.7441 - accuracy: 0.7447 - val_loss: 0.5770 - val_accuracy: 0.8231\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.57990 to 0.57705, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 31/100\n",
      "6985/6985 [==============================] - 0s 58us/step - loss: 0.7369 - accuracy: 0.7499 - val_loss: 0.5666 - val_accuracy: 0.8283\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.57705 to 0.56661, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 32/100\n",
      "6985/6985 [==============================] - 0s 55us/step - loss: 0.7178 - accuracy: 0.7581 - val_loss: 0.5734 - val_accuracy: 0.8283\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.56661\n",
      "Epoch 33/100\n",
      "6985/6985 [==============================] - 0s 57us/step - loss: 0.7074 - accuracy: 0.7575 - val_loss: 0.5697 - val_accuracy: 0.8231\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.56661\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6985/6985 [==============================] - 0s 55us/step - loss: 0.7054 - accuracy: 0.7572 - val_loss: 0.5493 - val_accuracy: 0.8323\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.56661 to 0.54934, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 35/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 0.7118 - accuracy: 0.7579 - val_loss: 0.5408 - val_accuracy: 0.8460\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.54934 to 0.54083, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 36/100\n",
      "6985/6985 [==============================] - 0s 58us/step - loss: 0.6964 - accuracy: 0.7622 - val_loss: 0.5458 - val_accuracy: 0.8346\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.54083\n",
      "Epoch 37/100\n",
      "6985/6985 [==============================] - 0s 53us/step - loss: 0.6729 - accuracy: 0.7714 - val_loss: 0.5214 - val_accuracy: 0.8403\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.54083 to 0.52139, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 38/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 0.6721 - accuracy: 0.7679 - val_loss: 0.5408 - val_accuracy: 0.8357\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.52139\n",
      "Epoch 39/100\n",
      "6985/6985 [==============================] - 0s 53us/step - loss: 0.6800 - accuracy: 0.7712 - val_loss: 0.5019 - val_accuracy: 0.8512\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.52139 to 0.50189, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 40/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 0.6735 - accuracy: 0.7771 - val_loss: 0.5355 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.50189\n",
      "Epoch 41/100\n",
      "6985/6985 [==============================] - 0s 53us/step - loss: 0.6664 - accuracy: 0.7748 - val_loss: 0.5446 - val_accuracy: 0.8392\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.50189\n",
      "Epoch 42/100\n",
      "6985/6985 [==============================] - 0s 53us/step - loss: 0.6420 - accuracy: 0.7790 - val_loss: 0.5028 - val_accuracy: 0.8477\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.50189\n",
      "Epoch 43/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.6532 - accuracy: 0.7759 - val_loss: 0.5212 - val_accuracy: 0.8483\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.50189\n",
      "Epoch 44/100\n",
      "6985/6985 [==============================] - 0s 58us/step - loss: 0.6417 - accuracy: 0.7805 - val_loss: 0.5025 - val_accuracy: 0.8529\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.50189\n",
      "Epoch 45/100\n",
      "6985/6985 [==============================] - 0s 60us/step - loss: 0.6765 - accuracy: 0.7702 - val_loss: 0.5055 - val_accuracy: 0.8414\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.50189\n",
      "Epoch 46/100\n",
      "6985/6985 [==============================] - 0s 53us/step - loss: 0.6493 - accuracy: 0.7805 - val_loss: 0.5054 - val_accuracy: 0.8523\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.50189\n",
      "Epoch 47/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 0.6401 - accuracy: 0.7900 - val_loss: 0.4841 - val_accuracy: 0.8540\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.50189 to 0.48409, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 48/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 0.6200 - accuracy: 0.7918 - val_loss: 0.4797 - val_accuracy: 0.8546\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.48409 to 0.47974, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 49/100\n",
      "6985/6985 [==============================] - 0s 57us/step - loss: 0.6241 - accuracy: 0.7873 - val_loss: 0.4686 - val_accuracy: 0.8626\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.47974 to 0.46858, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 50/100\n",
      "6985/6985 [==============================] - 0s 55us/step - loss: 0.6194 - accuracy: 0.7861 - val_loss: 0.4797 - val_accuracy: 0.8512\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.46858\n",
      "Epoch 51/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 0.6362 - accuracy: 0.7868 - val_loss: 0.4892 - val_accuracy: 0.8529\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.46858\n",
      "Epoch 52/100\n",
      "6985/6985 [==============================] - 0s 55us/step - loss: 0.6160 - accuracy: 0.7934 - val_loss: 0.4749 - val_accuracy: 0.8558\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.46858\n",
      "Epoch 53/100\n",
      "6985/6985 [==============================] - 0s 55us/step - loss: 0.6316 - accuracy: 0.7860 - val_loss: 0.4882 - val_accuracy: 0.8529\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.46858\n",
      "Epoch 54/100\n",
      "6985/6985 [==============================] - 0s 53us/step - loss: 0.6145 - accuracy: 0.7911 - val_loss: 0.4701 - val_accuracy: 0.8603\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.46858\n",
      "Epoch 55/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 0.6059 - accuracy: 0.7914 - val_loss: 0.4589 - val_accuracy: 0.8603\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.46858 to 0.45888, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 56/100\n",
      "6985/6985 [==============================] - 0s 55us/step - loss: 0.5993 - accuracy: 0.8011 - val_loss: 0.4774 - val_accuracy: 0.8620\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.45888\n",
      "Epoch 57/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 0.6032 - accuracy: 0.7937 - val_loss: 0.4779 - val_accuracy: 0.8609\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.45888\n",
      "Epoch 58/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 0.5826 - accuracy: 0.8029 - val_loss: 0.4756 - val_accuracy: 0.8580\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.45888\n",
      "Epoch 59/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 0.5850 - accuracy: 0.8033 - val_loss: 0.4632 - val_accuracy: 0.8540\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.45888\n",
      "Epoch 60/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 0.5928 - accuracy: 0.7963 - val_loss: 0.4622 - val_accuracy: 0.8569\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.45888\n",
      "Epoch 61/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 0.5814 - accuracy: 0.8001 - val_loss: 0.4536 - val_accuracy: 0.8689\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.45888 to 0.45362, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 62/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 0.5931 - accuracy: 0.7990 - val_loss: 0.4617 - val_accuracy: 0.8517\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.45362\n",
      "Epoch 63/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 0.5857 - accuracy: 0.8017 - val_loss: 0.4961 - val_accuracy: 0.8558\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.45362\n",
      "Epoch 64/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 0.5638 - accuracy: 0.8110 - val_loss: 0.4535 - val_accuracy: 0.8724\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.45362 to 0.45352, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 65/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 0.5672 - accuracy: 0.8067 - val_loss: 0.4351 - val_accuracy: 0.8701\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.45352 to 0.43510, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 66/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 0.5809 - accuracy: 0.8054 - val_loss: 0.4550 - val_accuracy: 0.8689\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.43510\n",
      "Epoch 67/100\n",
      "6985/6985 [==============================] - 0s 55us/step - loss: 0.5675 - accuracy: 0.8070 - val_loss: 0.4659 - val_accuracy: 0.8661\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.43510\n",
      "Epoch 68/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 0.5758 - accuracy: 0.8063 - val_loss: 0.4721 - val_accuracy: 0.8609\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.43510\n",
      "Epoch 69/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 0.5810 - accuracy: 0.8010 - val_loss: 0.4349 - val_accuracy: 0.8752\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.43510 to 0.43485, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 70/100\n",
      "6985/6985 [==============================] - 0s 55us/step - loss: 0.5519 - accuracy: 0.8122 - val_loss: 0.4390 - val_accuracy: 0.8746\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.43485\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6985/6985 [==============================] - 0s 53us/step - loss: 0.5690 - accuracy: 0.8092 - val_loss: 0.4710 - val_accuracy: 0.8666\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.43485\n",
      "Epoch 72/100\n",
      "6985/6985 [==============================] - 0s 53us/step - loss: 0.5677 - accuracy: 0.8093 - val_loss: 0.4581 - val_accuracy: 0.8643\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.43485\n",
      "Epoch 73/100\n",
      "6985/6985 [==============================] - 0s 53us/step - loss: 0.5640 - accuracy: 0.8102 - val_loss: 0.4474 - val_accuracy: 0.8706\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.43485\n",
      "Epoch 74/100\n",
      "6985/6985 [==============================] - 0s 53us/step - loss: 0.5582 - accuracy: 0.8126 - val_loss: 0.4456 - val_accuracy: 0.8712\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.43485\n",
      "Epoch 75/100\n",
      "6985/6985 [==============================] - 0s 53us/step - loss: 0.5535 - accuracy: 0.8140 - val_loss: 0.4398 - val_accuracy: 0.8724\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.43485\n",
      "Epoch 76/100\n",
      "6985/6985 [==============================] - 0s 53us/step - loss: 0.5493 - accuracy: 0.8195 - val_loss: 0.4472 - val_accuracy: 0.8683\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.43485\n",
      "Epoch 77/100\n",
      "6985/6985 [==============================] - 0s 53us/step - loss: 0.5262 - accuracy: 0.8209 - val_loss: 0.4313 - val_accuracy: 0.8718\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.43485 to 0.43131, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 78/100\n",
      "6985/6985 [==============================] - 0s 53us/step - loss: 0.5678 - accuracy: 0.8103 - val_loss: 0.4480 - val_accuracy: 0.8575\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.43131\n",
      "Epoch 79/100\n",
      "6985/6985 [==============================] - 0s 53us/step - loss: 0.5623 - accuracy: 0.8116 - val_loss: 0.4454 - val_accuracy: 0.8804\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.43131\n",
      "Epoch 80/100\n",
      "6985/6985 [==============================] - 0s 53us/step - loss: 0.5531 - accuracy: 0.8178 - val_loss: 0.4415 - val_accuracy: 0.8724\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.43131\n",
      "Epoch 81/100\n",
      "6985/6985 [==============================] - 0s 53us/step - loss: 0.5554 - accuracy: 0.8125 - val_loss: 0.4228 - val_accuracy: 0.8775\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.43131 to 0.42285, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 82/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 0.5408 - accuracy: 0.8183 - val_loss: 0.4244 - val_accuracy: 0.8832\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.42285\n",
      "Epoch 83/100\n",
      "6985/6985 [==============================] - 0s 53us/step - loss: 0.5184 - accuracy: 0.8276 - val_loss: 0.4309 - val_accuracy: 0.8683\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.42285\n",
      "Epoch 84/100\n",
      "6985/6985 [==============================] - 0s 53us/step - loss: 0.5567 - accuracy: 0.8130 - val_loss: 0.4053 - val_accuracy: 0.8804\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.42285 to 0.40526, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 85/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 0.5482 - accuracy: 0.8228 - val_loss: 0.4501 - val_accuracy: 0.8632\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.40526\n",
      "Epoch 86/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 0.5272 - accuracy: 0.8192 - val_loss: 0.4259 - val_accuracy: 0.8786\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.40526\n",
      "Epoch 87/100\n",
      "6985/6985 [==============================] - 0s 53us/step - loss: 0.5195 - accuracy: 0.8253 - val_loss: 0.4352 - val_accuracy: 0.8752\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.40526\n",
      "Epoch 88/100\n",
      "6985/6985 [==============================] - 0s 53us/step - loss: 0.5232 - accuracy: 0.8241 - val_loss: 0.4265 - val_accuracy: 0.8809\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.40526\n",
      "Epoch 89/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 0.5358 - accuracy: 0.8262 - val_loss: 0.4284 - val_accuracy: 0.8678\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.40526\n",
      "Epoch 90/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 0.5404 - accuracy: 0.8203 - val_loss: 0.4113 - val_accuracy: 0.8769\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.40526\n",
      "Epoch 91/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 0.5350 - accuracy: 0.8185 - val_loss: 0.4111 - val_accuracy: 0.8786\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.40526\n",
      "Epoch 92/100\n",
      "6985/6985 [==============================] - 0s 53us/step - loss: 0.5415 - accuracy: 0.8218 - val_loss: 0.4133 - val_accuracy: 0.8786\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.40526\n",
      "Epoch 93/100\n",
      "6985/6985 [==============================] - 0s 55us/step - loss: 0.5164 - accuracy: 0.8296 - val_loss: 0.4084 - val_accuracy: 0.8838\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.40526\n",
      "Epoch 94/100\n",
      "6985/6985 [==============================] - 0s 53us/step - loss: 0.5050 - accuracy: 0.8335 - val_loss: 0.4162 - val_accuracy: 0.8729\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.40526\n",
      "Epoch 95/100\n",
      "6985/6985 [==============================] - 1s 73us/step - loss: 0.5124 - accuracy: 0.8298 - val_loss: 0.3998 - val_accuracy: 0.8849\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.40526 to 0.39984, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 96/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 0.5262 - accuracy: 0.8242 - val_loss: 0.3979 - val_accuracy: 0.8890\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.39984 to 0.39787, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 97/100\n",
      "6985/6985 [==============================] - 0s 54us/step - loss: 0.5151 - accuracy: 0.8291 - val_loss: 0.3835 - val_accuracy: 0.8844\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.39787 to 0.38354, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 98/100\n",
      "6985/6985 [==============================] - 0s 55us/step - loss: 0.5098 - accuracy: 0.8281 - val_loss: 0.4079 - val_accuracy: 0.8769\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.38354\n",
      "Epoch 99/100\n",
      "6985/6985 [==============================] - 0s 66us/step - loss: 0.5251 - accuracy: 0.8258 - val_loss: 0.4327 - val_accuracy: 0.8655\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.38354\n",
      "Epoch 100/100\n",
      "6985/6985 [==============================] - 0s 53us/step - loss: 0.5238 - accuracy: 0.8223 - val_loss: 0.4172 - val_accuracy: 0.8758\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.38354\n",
      "Training completed in time:  0:00:40.019410\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_mlp.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9234073162078857\n",
      "Testing Accuracy:  0.875787079334259\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa \n",
    "import numpy as np \n",
    "\n",
    "def extract_feature(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio_data, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file)\n",
    "        return None, None\n",
    "\n",
    "    return np.array([mfccsscaled])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction(file_name):\n",
    "    prediction_feature = extract_feature(file_name) \n",
    "\n",
    "    predicted_vector = model.predict_classes(prediction_feature)\n",
    "    predicted_class = le.inverse_transform(predicted_vector) \n",
    "    print(\"The predicted class is:\", predicted_class[0], '\\n') \n",
    "\n",
    "    predicted_proba_vector = model.predict_proba(prediction_feature) \n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    for i in range(len(predicted_proba)): \n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: air_conditioner \n",
      "\n",
      "air_conditioner \t\t :  0.99335587024688720703125000000000\n",
      "car_horn \t\t :  0.00037299151881597936153411865234\n",
      "children_playing \t\t :  0.00306214927695691585540771484375\n",
      "dog_bark \t\t :  0.00049450801452621817588806152344\n",
      "drilling \t\t :  0.00102501001674681901931762695312\n",
      "engine_idling \t\t :  0.00041796520235948264598846435547\n",
      "gun_shot \t\t :  0.00017374681192450225353240966797\n",
      "jackhammer \t\t :  0.00025677989469841122627258300781\n",
      "siren \t\t :  0.00008661708125146105885505676270\n",
      "street_music \t\t :  0.00075439002830535173416137695312\n"
     ]
    }
   ],
   "source": [
    "# Class: Air Conditioner\n",
    "\n",
    "filename = '../UrbanSound Dataset sample/audio/100852-0-0-0.wav' \n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: drilling \n",
      "\n",
      "air_conditioner \t\t :  0.00000000002954743047456354076985\n",
      "car_horn \t\t :  0.00000004498385308693286788184196\n",
      "children_playing \t\t :  0.00000009097045960970717715099454\n",
      "dog_bark \t\t :  0.00001219696969201322644948959351\n",
      "drilling \t\t :  0.84448534250259399414062500000000\n",
      "engine_idling \t\t :  0.00000000005938301239627463701254\n",
      "gun_shot \t\t :  0.00000001138661431809850910212845\n",
      "jackhammer \t\t :  0.00000007531855317211011424660683\n",
      "siren \t\t :  0.00000000016324280815993574833556\n",
      "street_music \t\t :  0.15550225973129272460937500000000\n"
     ]
    }
   ],
   "source": [
    "# Class: Drilling\n",
    "\n",
    "filename = '../UrbanSound Dataset sample/audio/103199-4-0-0.wav'\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: street_music \n",
      "\n",
      "air_conditioner \t\t :  0.06953979283571243286132812500000\n",
      "car_horn \t\t :  0.00319060729816555976867675781250\n",
      "children_playing \t\t :  0.32431581616401672363281250000000\n",
      "dog_bark \t\t :  0.04136848449707031250000000000000\n",
      "drilling \t\t :  0.01034335140138864517211914062500\n",
      "engine_idling \t\t :  0.01424244791269302368164062500000\n",
      "gun_shot \t\t :  0.00735182501375675201416015625000\n",
      "jackhammer \t\t :  0.01719676516950130462646484375000\n",
      "siren \t\t :  0.00356682133860886096954345703125\n",
      "street_music \t\t :  0.50888413190841674804687500000000\n"
     ]
    }
   ],
   "source": [
    "# Class: Street music \n",
    "\n",
    "filename = '../UrbanSound Dataset sample/audio/101848-9-0-0.wav'\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: car_horn \n",
      "\n",
      "air_conditioner \t\t :  0.00195233745034784078598022460938\n",
      "car_horn \t\t :  0.44798901677131652832031250000000\n",
      "children_playing \t\t :  0.00401515932753682136535644531250\n",
      "dog_bark \t\t :  0.08147097378969192504882812500000\n",
      "drilling \t\t :  0.19299563765525817871093750000000\n",
      "engine_idling \t\t :  0.00327378232032060623168945312500\n",
      "gun_shot \t\t :  0.00266797910444438457489013671875\n",
      "jackhammer \t\t :  0.00223159301094710826873779296875\n",
      "siren \t\t :  0.00225371075794100761413574218750\n",
      "street_music \t\t :  0.26114973425865173339843750000000\n"
     ]
    }
   ],
   "source": [
    "# Class: Car Horn \n",
    "\n",
    "filename = '../UrbanSound Dataset sample/audio/100648-1-0-0.wav'\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: siren \n",
      "\n",
      "air_conditioner \t\t :  0.00000670817780701327137649059296\n",
      "car_horn \t\t :  0.00001657246320974081754684448242\n",
      "children_playing \t\t :  0.00820563081651926040649414062500\n",
      "dog_bark \t\t :  0.10819123685359954833984375000000\n",
      "drilling \t\t :  0.00002395880073891021311283111572\n",
      "engine_idling \t\t :  0.15318980813026428222656250000000\n",
      "gun_shot \t\t :  0.00020229481742717325687408447266\n",
      "jackhammer \t\t :  0.00039551217923872172832489013672\n",
      "siren \t\t :  0.71456593275070190429687500000000\n",
      "street_music \t\t :  0.01520238630473613739013671875000\n"
     ]
    }
   ],
   "source": [
    "filename = '../Evaluation audio/siren_1.wav'\n",
    "\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
