{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import warnings                        # To ignore any warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import glob \n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf; print('tensorflow version: ', tf.__version__)\n",
    "import keras; print('keras version: ',keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR=\"input/\"\n",
    "# 16 KHz\n",
    "SAMPLE_RATE = 16000\n",
    "# seconds\n",
    "MAX_SOUND_CLIP_DURATION=12   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd\n",
    "!ls -all ../input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_a=pd.read_csv(INPUT_DIR+\"/set_a.csv\")\n",
    "set_a.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_a_timing=pd.read_csv(INPUT_DIR+\"/set_a_timing.csv\")\n",
    "set_a_timing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_b=pd.read_csv(INPUT_DIR+\"/set_b.csv\")\n",
    "set_b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [set_a, set_b]\n",
    "train_ab=pd.concat(frames)\n",
    "train_ab.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes=train_ab.label.unique()\n",
    "\n",
    "print(\"Number of training examples=\", train_ab.shape[0], \"  Number of classes=\", len(train_ab.label.unique()))\n",
    "print (nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_group = train_ab.groupby(['label','dataset']).count()\n",
    "plot = category_group.unstack().reindex(category_group.unstack().sum(axis=1).sort_values().index)\\\n",
    "          .plot(kind='bar', stacked=True, title=\"Number of Audio Samples per Category\", figsize=(16,5))\n",
    "plot.set_xlabel(\"Category\")\n",
    "plot.set_ylabel(\"Samples Count\");\n",
    "\n",
    "print('Min samples per category = ', min(train_ab.label.value_counts()))\n",
    "print('Max samples per category = ', max(train_ab.label.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Minimum samples per category = ', min(train_ab.label.value_counts()))\n",
    "print('Maximum samples per category = ', max(train_ab.label.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_file=INPUT_DIR+\"/set_a/normal__201106111136.wav\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heart it\n",
    "import IPython.display as ipd\n",
    "ipd.Audio(normal_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load use wave \n",
    "import wave\n",
    "wav = wave.open(normal_file)\n",
    "print(\"Sampling (frame) rate = \", wav.getframerate())\n",
    "print(\"Total samples (frames) = \", wav.getnframes())\n",
    "print(\"Duration = \", wav.getnframes()/wav.getframerate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load use scipy\n",
    "from scipy.io import wavfile\n",
    "rate, data = wavfile.read(normal_file)\n",
    "print(\"Sampling (frame) rate = \", rate)\n",
    "print(\"Total samples (frames) = \", data.shape)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot wave by audio frames\n",
    "plt.figure(figsize=(16, 3))\n",
    "plt.plot(data, '-', );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load using Librosa\n",
    "y, sr = librosa.load(normal_file, duration=5)   #default sampling rate is 22 HZ\n",
    "dur=librosa.get_duration(y)\n",
    "print (\"duration:\", dur)\n",
    "print(y.shape, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librosa plot\n",
    "plt.figure(figsize=(16, 3))\n",
    "librosa.display.waveplot(y, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# murmur case\n",
    "murmur_file=INPUT_DIR+\"/set_a/murmur__201108222231.wav\"\n",
    "y2, sr2 = librosa.load(murmur_file,duration=5)\n",
    "dur=librosa.get_duration(y)\n",
    "print (\"duration:\", dur)\n",
    "print(y2.shape,sr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heart it\n",
    "import IPython.display as ipd\n",
    "ipd.Audio(murmur_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show it\n",
    "plt.figure(figsize=(16, 3))\n",
    "librosa.display.waveplot(y2, sr=sr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrasystole case\n",
    "extrastole_file=INPUT_DIR+\"/set_b/extrastole__127_1306764300147_C2.wav\"\n",
    "y3, sr3 = librosa.load(extrastole_file, duration=5)\n",
    "dur=librosa.get_duration(y)\n",
    "print (\"duration:\", dur)\n",
    "print(y3.shape,sr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heart it\n",
    "import IPython.display as ipd\n",
    "ipd.Audio(extrastole_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show it\n",
    "plt.figure(figsize=(16, 3))\n",
    "librosa.display.waveplot(y3, sr=sr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample file\n",
    "artifact_file=INPUT_DIR+\"/set_a/artifact__201012172012.wav\"\n",
    "y4, sr4 = librosa.load(artifact_file, duration=5)\n",
    "dur=librosa.get_duration(y)\n",
    "print (\"duration:\", dur)\n",
    "print(y4.shape,sr4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heart it\n",
    "import IPython.display as ipd\n",
    "ipd.Audio(artifact_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show it\n",
    "plt.figure(figsize=(16, 3))\n",
    "librosa.display.waveplot(y4, sr=sr4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample file\n",
    "extrahls_file=INPUT_DIR+\"/set_a/extrahls__201101070953.wav\"\n",
    "y5, sr5 = librosa.load(extrahls_file, duration=5)\n",
    "dur=librosa.get_duration(y)\n",
    "print (\"duration:\", dur)\n",
    "print(y5.shape,sr5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heart it\n",
    "import IPython.display as ipd\n",
    "ipd.Audio(extrahls_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show it\n",
    "plt.figure(figsize=(16, 3))\n",
    "librosa.display.waveplot(y5, sr=sr5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's a sample generate mfccs from a wave file\n",
    "normal_file=INPUT_DIR+\"/set_a/normal__201106111136.wav\"\n",
    "#y, sr = librosa.load(sample_file, offset=7, duration=7)\n",
    "y, sr = librosa.load(normal_file)\n",
    "mfccs = librosa.feature.mfcc(y=y, sr=sr)\n",
    "print (mfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pre-computed log-power Mel spectrogram\n",
    "S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128,fmax=8000)\n",
    "log_S=librosa.feature.mfcc(S=librosa.power_to_db(S))\n",
    "print (log_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get more components\n",
    "mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "#print (mfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the MFCC series\n",
    "# Mel-frequency cepstral coefficients (MFCCs)\n",
    "plt.figure(figsize=(12, 3))\n",
    "librosa.display.specshow(mfccs, x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('Mel-frequency cepstral coefficients (MFCCs)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different DCT bases\n",
    "m_slaney = librosa.feature.mfcc(y=y, sr=sr, dct_type=2)\n",
    "\n",
    "#m_dct1 = librosa.feature.mfcc(y=y, sr=sr, dct_type=1)\n",
    "plt.figure(figsize=(12, 6))\n",
    "#plt.subplot(3, 1, 1)\n",
    "#librosa.display.specshow(m_dct1, x_axis='time')\n",
    "#plt.title('Discrete cosine transform (dct_type=1)')\n",
    "#plt.colorbar()\n",
    "m_htk = librosa.feature.mfcc(y=y, sr=sr, dct_type=3)\n",
    "plt.subplot(3, 1, 2)\n",
    "librosa.display.specshow(m_slaney, x_axis='time')\n",
    "plt.title('RASTAMAT / Auditory toolbox (dct_type=2)')\n",
    "plt.colorbar()\n",
    "plt.subplot(3, 1, 3)\n",
    "librosa.display.specshow(m_htk, x_axis='time')\n",
    "plt.title('HTK-style (dct_type=3)')\n",
    "plt.colorbar()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get onset times from a signal\n",
    "onset_frames = librosa.onset.onset_detect(y=y, sr=sr)\n",
    "librosa.frames_to_time(onset_frames, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a pre-computed onset envelope\n",
    "o_env = librosa.onset.onset_strength(y, sr=sr)\n",
    "times = librosa.frames_to_time(np.arange(len(o_env)), sr=sr)\n",
    "onset_frames = librosa.onset.onset_detect(onset_envelope=o_env, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize it\n",
    "D = np.abs(librosa.stft(y))\n",
    "plt.figure(figsize=(16, 6))\n",
    "ax1 = plt.subplot(2, 1, 1)\n",
    "librosa.display.specshow(librosa.amplitude_to_db(D, ref=np.max),x_axis='time', y_axis='log')\n",
    "plt.title('Power spectrogram')\n",
    "plt.subplot(2, 1, 2, sharex=ax1)\n",
    "\n",
    "plt.plot(times, o_env, label='Onset strength')\n",
    "plt.vlines(times[onset_frames], 0, o_env.max(), color='r', alpha=0.9,linestyle='--', label='Onsets')\n",
    "plt.axis('tight')\n",
    "plt.legend(frameon=True, framealpha=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oenv = librosa.onset.onset_strength(y=y, sr=sr)\n",
    "# Detect events without backtracking\n",
    "onset_raw = librosa.onset.onset_detect(onset_envelope=oenv, backtrack=False)\n",
    "# Backtrack the events using the onset envelope\n",
    "onset_bt = librosa.onset.onset_backtrack(onset_raw, oenv)\n",
    "# Backtrack the events using the RMS values\n",
    "rms = librosa.feature.rms(S=np.abs(librosa.stft(y=y)))\n",
    "onset_bt_rms = librosa.onset.onset_backtrack(onset_raw, rms[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(oenv, label='Onset strength')\n",
    "plt.vlines(onset_raw, 0, oenv.max(), label='Raw onsets')\n",
    "plt.vlines(onset_bt, 0, oenv.max(), label='Backtracked', color='r')\n",
    "plt.legend(frameon=True, framealpha=0.75)\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(rms[0], label='RMS')\n",
    "plt.vlines(onset_bt_rms, 0, rms.max(), label='Backtracked (RMS)', color='r')\n",
    "plt.legend(frameon=True, framealpha=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.abs(librosa.stft(y))\n",
    "times = librosa.frames_to_time(np.arange(D.shape[1]))\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "#ax1 = plt.subplot(2, 1, 1)\n",
    "#librosa.display.specshow(librosa.amplitude_to_db(D, ref=np.max),y_axis='log', x_axis='time')\n",
    "#plt.title('Power spectrogram')\n",
    "\n",
    "# Construct a standard onset function\n",
    "onset_env = librosa.onset.onset_strength(y=y, sr=sr)\n",
    "plt.subplot(2, 1, 1, sharex=ax1)\n",
    "plt.plot(times, 2 + onset_env / onset_env.max(), alpha=0.8,label='Mean (mel)')\n",
    "\n",
    "# median\n",
    "onset_env = librosa.onset.onset_strength(y=y, sr=sr,aggregate=np.median,fmax=8000, n_mels=256)\n",
    "plt.plot(times, 1+ (onset_env/onset_env.max()), alpha=0.8,label='Median (custom mel)')\n",
    "\n",
    "# Constant-Q spectrogram instead of Mel\n",
    "onset_env = librosa.onset.onset_strength(y=y, sr=sr,feature=librosa.cqt)\n",
    "plt.plot(times, onset_env / onset_env.max(), alpha=0.8,label='Mean (CQT)')\n",
    "plt.legend(frameon=True, framealpha=0.75)\n",
    "plt.ylabel('Normalized strength')\n",
    "plt.yticks([])\n",
    "plt.axis('tight')\n",
    "plt.tight_layout()\n",
    "\n",
    "onset_subbands = librosa.onset.onset_strength_multi(y=y, sr=sr, channels=[0, 32, 64, 96, 128])\n",
    "#plt.figure(figsize=(16, 6))\n",
    "plt.subplot(2, 1, 2)\n",
    "librosa.display.specshow(onset_subbands, x_axis='time')\n",
    "plt.ylabel('Sub-bands')\n",
    "plt.title('Sub-band onset strength')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of training examples=\", train_ab.shape[0], \"  Number of classes=\", len(train_ab.label.unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_norm(data):\n",
    "    max_data = np.max(data)\n",
    "    min_data = np.min(data)\n",
    "    data = (data-min_data)/(max_data-min_data+0.0001)\n",
    "    return data-0.5\n",
    "\n",
    "# get audio data without padding highest qualify audio\n",
    "def load_file_data_without_change(folder,file_names, duration=3, sr=16000):\n",
    "    input_length=sr*duration\n",
    "    # function to load files and extract features\n",
    "    # file_names = glob.glob(os.path.join(folder, '*.wav'))\n",
    "    data = []\n",
    "    for file_name in file_names:\n",
    "        try:\n",
    "            sound_file=folder+file_name\n",
    "            print (\"load file \",sound_file)\n",
    "            # use kaiser_fast technique for faster extraction\n",
    "            X, sr = librosa.load( sound_file, res_type='kaiser_fast') \n",
    "            dur = librosa.get_duration(y=X, sr=sr)\n",
    "            # extract normalized mfcc feature from data\n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sr, n_mfcc=40).T,axis=0) \n",
    "        except Exception as e:\n",
    "            print(\"Error encountered while parsing file: \", file)\n",
    "        feature = np.array(mfccs).reshape([-1,1])\n",
    "        data.append(feature)\n",
    "    return data\n",
    "\n",
    "\n",
    "# get audio data with a fix padding may also chop off some file\n",
    "def load_file_data (folder,file_names, duration=12, sr=16000):\n",
    "    input_length=sr*duration\n",
    "    # function to load files and extract features\n",
    "    # file_names = glob.glob(os.path.join(folder, '*.wav'))\n",
    "    data = []\n",
    "    for file_name in file_names:\n",
    "        try:\n",
    "            sound_file=folder+file_name\n",
    "            print (\"load file \",sound_file)\n",
    "            # use kaiser_fast technique for faster extraction\n",
    "            X, sr = librosa.load( sound_file, sr=sr, duration=duration,res_type='kaiser_fast') \n",
    "            dur = librosa.get_duration(y=X, sr=sr)\n",
    "            # pad audio file same duration\n",
    "            if (round(dur) < duration):\n",
    "                print (\"fixing audio lenght :\", file_name)\n",
    "                y = librosa.util.fix_length(X, input_length)                \n",
    "            #normalized raw audio \n",
    "            # y = audio_norm(y)            \n",
    "            # extract normalized mfcc feature from data\n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sr, n_mfcc=40).T,axis=0)             \n",
    "        except Exception as e:\n",
    "            print(\"Error encountered while parsing file: \", file)        \n",
    "        feature = np.array(mfccs).reshape([-1,1])\n",
    "        data.append(feature)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple encoding of categories, limited to 3 types\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Map label text to integer\n",
    "CLASSES = ['artifact','murmur','normal']\n",
    "# {'artifact': 0, 'murmur': 1, 'normal': 3}\n",
    "NB_CLASSES=len(CLASSES)\n",
    "\n",
    "# Map integer value to text labels\n",
    "label_to_int = {k:v for v,k in enumerate(CLASSES)}\n",
    "print (label_to_int)\n",
    "print (\" \")\n",
    "# map integer to label text\n",
    "int_to_label = {v:k for k,v in label_to_int.items()}\n",
    "print(int_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset-a, keep them separate for testing purpose\n",
    "import os, fnmatch\n",
    "\n",
    "A_folder=INPUT_DIR+'/set_a/'\n",
    "# set-a\n",
    "A_artifact_files = fnmatch.filter(os.listdir(INPUT_DIR+'/set_a'), 'artifact*.wav')\n",
    "A_artifact_sounds = load_file_data(folder=A_folder,file_names=A_artifact_files, duration=MAX_SOUND_CLIP_DURATION)\n",
    "A_artifact_labels = [0 for items in A_artifact_files]\n",
    "\n",
    "A_normal_files = fnmatch.filter(os.listdir(INPUT_DIR+'/set_a'), 'normal*.wav')\n",
    "A_normal_sounds = load_file_data(folder=A_folder,file_names=A_normal_files, duration=MAX_SOUND_CLIP_DURATION)\n",
    "A_normal_labels = [2 for items in A_normal_sounds]\n",
    "\n",
    "A_extrahls_files = fnmatch.filter(os.listdir(INPUT_DIR+'/set_a'), 'extrahls*.wav')\n",
    "A_extrahls_sounds = load_file_data(folder=A_folder,file_names=A_extrahls_files, duration=MAX_SOUND_CLIP_DURATION)\n",
    "A_extrahls_labels = [1 for items in A_extrahls_sounds]\n",
    "\n",
    "A_murmur_files = fnmatch.filter(os.listdir(INPUT_DIR+'/set_a'), 'murmur*.wav')\n",
    "A_murmur_sounds = load_file_data(folder=A_folder,file_names=A_murmur_files, duration=MAX_SOUND_CLIP_DURATION)\n",
    "A_murmur_labels = [1 for items in A_murmur_files]\n",
    "\n",
    "# test files\n",
    "A_unlabelledtest_files = fnmatch.filter(os.listdir(INPUT_DIR+'/set_a'), 'Aunlabelledtest*.wav')\n",
    "A_unlabelledtest_sounds = load_file_data(folder=A_folder,file_names=A_unlabelledtest_files, duration=MAX_SOUND_CLIP_DURATION)\n",
    "A_unlabelledtest_labels = [-1 for items in A_unlabelledtest_sounds]\n",
    "\n",
    "print (\"loaded dataset-a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# load dataset-b, keep them separate for testing purpose \n",
    "B_folder=INPUT_DIR+'/set_b/'\n",
    "# set-b\n",
    "B_normal_files = fnmatch.filter(os.listdir(INPUT_DIR+'/set_b'), 'normal*.wav')  # include noisy files\n",
    "B_normal_sounds = load_file_data(folder=B_folder,file_names=B_normal_files, duration=MAX_SOUND_CLIP_DURATION)\n",
    "B_normal_labels = [2 for items in B_normal_sounds]\n",
    "\n",
    "B_murmur_files = fnmatch.filter(os.listdir(INPUT_DIR+'/set_b'), 'murmur*.wav')  # include noisy files\n",
    "B_murmur_sounds = load_file_data(folder=B_folder,file_names=B_murmur_files, duration=MAX_SOUND_CLIP_DURATION)\n",
    "B_murmur_labels = [1 for items in B_murmur_files]\n",
    "\n",
    "B_extrastole_files = fnmatch.filter(os.listdir(INPUT_DIR+'/set_b'), 'extrastole*.wav')\n",
    "B_extrastole_sounds = load_file_data(folder=B_folder,file_names=B_extrastole_files, duration=MAX_SOUND_CLIP_DURATION)\n",
    "B_extrastole_labels = [1 for items in B_extrastole_files]\n",
    "\n",
    "#test files\n",
    "B_unlabelledtest_files = fnmatch.filter(os.listdir(INPUT_DIR+'/set_b'), 'Bunlabelledtest*.wav')\n",
    "B_unlabelledtest_sounds = load_file_data(folder=B_folder,file_names=B_unlabelledtest_files, duration=MAX_SOUND_CLIP_DURATION)\n",
    "B_unlabelledtest_labels = [-1 for items in B_unlabelledtest_sounds]\n",
    "print (\"loaded dataset-b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine set-a and set-b \n",
    "x_data = np.concatenate((A_artifact_sounds, A_normal_sounds,A_extrahls_sounds,A_murmur_sounds, \n",
    "                         B_normal_sounds,B_murmur_sounds,B_extrastole_sounds))\n",
    "\n",
    "y_data = np.concatenate((A_artifact_labels, A_normal_labels,A_extrahls_labels,A_murmur_labels,\n",
    "                         B_normal_labels,B_murmur_labels,B_extrastole_labels))\n",
    "\n",
    "test_x = np.concatenate((A_unlabelledtest_sounds,B_unlabelledtest_sounds))\n",
    "test_y = np.concatenate((A_unlabelledtest_labels,B_unlabelledtest_labels))\n",
    "\n",
    "print (\"combined training data record: \",len(y_data), len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "# shuffle - whether or not to shuffle the data before splitting. If shuffle=False then stratify must be None.\n",
    "# random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by np.random.\n",
    "\n",
    "seed = 1000\n",
    "# split data into Train, Validation and Test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, train_size=0.9, random_state=seed, shuffle=True)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, train_size=0.9, random_state=seed, shuffle=True)\n",
    "\n",
    "# One-Hot encoding for classes\n",
    "y_train = np.array(keras.utils.to_categorical(y_train, len(CLASSES)))\n",
    "y_test = np.array(keras.utils.to_categorical(y_test, len(CLASSES)))\n",
    "y_val = np.array(keras.utils.to_categorical(y_val, len(CLASSES)))\n",
    "test_y=np.array(keras.utils.to_categorical(test_y, len(CLASSES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"label shape: \", y_data.shape)\n",
    "print (\"data size of the array: : %s\" % y_data.size)\n",
    "print (\"length of one array element in bytes: \", y_data.itemsize)\n",
    "print (\"total bytes consumed by the elements of the array: \", y_data.nbytes)\n",
    "print (y_data[1])\n",
    "print (\"\")\n",
    "print (\"audio data shape: \", x_data.shape)\n",
    "print (\"data size of the array: : %s\" % x_data.size)\n",
    "print (\"length of one array element in bytes: \", x_data.itemsize)\n",
    "print (\"total bytes consumed by the elements of the array: \", x_data.nbytes)\n",
    "#print (x_data[1])\n",
    "print (\"\")\n",
    "print (\"training data shape: \", x_train.shape)\n",
    "print (\"training label shape: \", y_train.shape)\n",
    "print (\"\")\n",
    "print (\"validation data shape: \", x_val.shape)\n",
    "print (\"validation label shape: \", y_val.shape)\n",
    "print (\"\")\n",
    "print (\"test data shape: \", x_test.shape)\n",
    "print (\"test label shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint,TensorBoard,ProgbarLogger\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build LSTM RNN model ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ca50665a3d0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Build LSTM RNN model ...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurrent_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurrent_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "print('Build LSTM RNN model ...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=64, dropout=0.05, recurrent_dropout=0.20, return_sequences=True,input_shape = (40,1)))\n",
    "model.add(LSTM(units=32, dropout=0.05, recurrent_dropout=0.20, return_sequences=False))\n",
    "model.add(Dense(len(CLASSES), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adamax', metrics=['acc','mse', 'mae', 'mape', 'cosine'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ReduceLROnPlateau' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ReduceLROnPlateau' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# saved model checkpoint file\n",
    "best_model_file=\"./best_model_trained.hdf5\"\n",
    "#train_model_file=file_path+\"/checkpoints/weights.best_{epoch:02d}-{loss:.2f}.hdf5\"\n",
    "MAX_PATIENT=12\n",
    "MAX_EPOCHS=100\n",
    "MAX_BATCH=32\n",
    "\n",
    "# callbacks\n",
    "# removed EarlyStopping(patience=MAX_PATIENT)\n",
    "callback=[ReduceLROnPlateau(patience=MAX_PATIENT, verbose=1),\n",
    "          ModelCheckpoint(filepath=best_model_file, monitor='loss', verbose=1, save_best_only=True)]\n",
    "\n",
    "print (\"training started..... please wait.\")\n",
    "# training\n",
    "history=model.fit(x_train, y_train, \n",
    "                  batch_size=MAX_BATCH, \n",
    "                  epochs=MAX_EPOCHS,\n",
    "                  verbose=0,\n",
    "                  validation_data=(x_val, y_val),\n",
    "                  callbacks=callback) \n",
    "\n",
    "print (\"training finised!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-169930d3070a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Keras reported accuracy:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"model train data score       : \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m\"%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#Model Evaluation\n",
    "\n",
    "# Keras reported accuracy:\n",
    "score = model.evaluate(x_train, y_train, verbose=0) \n",
    "print (\"model train data score       : \",round(score[1]*100) , \"%\")\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0) \n",
    "print (\"model test data score        : \",round(score[1]*100) , \"%\")\n",
    "\n",
    "score = model.evaluate(x_val, y_val, verbose=0) \n",
    "print (\"model validation data score  : \", round(score[1]*100), \"%\")\n",
    "\n",
    "score = model.evaluate(test_x, test_y, verbose=0) \n",
    "print (\"model unlabeled data score   : \", round(score[1]*100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Plot Keras History\n",
    "#Plot loss and accuracy for the training and validation set.\n",
    "def plot_history(history):\n",
    "    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
    "    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
    "    if len(loss_list) == 0:\n",
    "        print('Loss is missing in history')\n",
    "        return \n",
    "    plt.figure(figsize=(22,10))\n",
    "    ## As loss always exists\n",
    "    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
    "    ## Accuracy\n",
    "    plt.figure(221, figsize=(20,10))\n",
    "    ## Accuracy\n",
    "    # plt.figure(2,figsize=(14,5))\n",
    "    plt.subplot(221, title='Accuracy')\n",
    "    for l in acc_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "    for l in val_acc_list:    \n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    ## Loss\n",
    "    plt.subplot(222, title='Loss')\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))    \n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# plot history\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c7c8e3f3393b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m def plot_confusion_matrix(cm, classes,\n\u001b[1;32m      2\u001b[0m                           \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                           cmap=plt.cm.Blues):\n\u001b[0m\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[1;32m      5\u001b[0m     \u001b[0mThis\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mprints\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mplots\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconfusion\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        title='Normalized confusion matrix'\n",
    "    else:\n",
    "        title='Confusion matrix'\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-45dd6398801b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# prediction class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"prediction test return :\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_to_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# prediction class \n",
    "y_pred = model.predict_classes(x_test, batch_size=32)\n",
    "print (\"prediction test return :\",y_pred[1], \"-\", int_to_label[y_pred[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0c18da63653a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# plot Classification Metrics: Accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m221\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Prediction'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(1,figsize=(20,10))\n",
    "# plot Classification Metrics: Accuracy \n",
    "plt.subplot(221, title='Prediction')\n",
    "plt.plot(y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./best_model_trained.hdf5\n"
     ]
    }
   ],
   "source": [
    "print (best_model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "### Loading a Check-Pointed Neural Network Model\n",
    "# How to load and use weights from a checkpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# create model\n",
    "print('Build LSTM RNN model ...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=64, dropout=0.05, recurrent_dropout=0.35, return_sequences=True,input_shape = (40,1)))\n",
    "model.add(LSTM(units=32, dropout=0.05, recurrent_dropout=0.35, return_sequences=False))\n",
    "model.add(Dense(len(CLASSES), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc','mse', 'mae', 'mape', 'cosine'])\n",
    "model.summary()\n",
    "# load weights\n",
    "model.load_weights(best_model_file)\n",
    "# Compile model (required to make predictions)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(\"Created model and loaded weights from file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8bf22d56b146>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# make a prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#check scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Model evaluation accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "y_pred = model.predict_classes(x_test, batch_size=32)\n",
    "#check scores\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print (\"Model evaluation accuracy: \", round(scores[1]*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
